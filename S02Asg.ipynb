{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c12e37-b95a-4750-a187-b318deaef19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\tFind the PriceGain, PriceGainP, VolumeGain, VolumeGainP of each stock for 10 days [Refer Point 1] from historical data, write the results to JSON, Parquet, ORC, \n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed91c2ce-01cd-498f-a771-c14935ee7290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 05:23:37 WARN Utils: Your hostname, ubuntu-virtual-machine resolves to a loopback address: 127.0.1.1; using 192.168.80.128 instead (on interface ens33)\n",
      "22/03/12 05:23:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "22/03/12 05:23:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "config = SparkConf()\n",
    "config.setMaster(\"local\").setAppName(\"DataFrameAsg02\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.config(conf=config).getOrCreate()\n",
    "\n",
    "sc= spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417206cb-dfed-4524-a644-571ff64807d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SYMBOL,SERIES,OPEN,HIGH,LOW,CLOSE,LAST,PREVCLOSE,TOTTRDQTY,TOTTRDVAL,TIMESTAMP,TOTALTRADES,ISIN,\n",
    "from pyspark.sql.types import StructType, LongType, StringType, IntegerType, DoubleType, DateType, TimestampType\n",
    "\n",
    "stockSchema = StructType()\\\n",
    "                    .add(\"SYMBOL\", StringType(),True)\\\n",
    "                    .add(\"SERIES\", StringType(),True)\\\n",
    "                    .add(\"OPEN\", DoubleType(),True)\\\n",
    "                    .add(\"HIGH\", DoubleType(),True)\\\n",
    "                    .add(\"LOW\", DoubleType(),True)\\\n",
    "                    .add(\"CLOSE\", DoubleType(),True)\\\n",
    "                    .add(\"LAST\", DoubleType(),True)\\\n",
    "                    .add(\"PREVCLOSE\", DoubleType(),True)\\\n",
    "                    .add(\"TOTTRDQTY\", IntegerType(),True)\\\n",
    "                    .add(\"TOTTRDVAL\", DoubleType(),True)\\\n",
    "                    .add(\"TIMESTAMP\", StringType(),True)\\\n",
    "                    .add(\"TOTALTRADES\", IntegerType(),True)\\\n",
    "                    .add(\"ISIN\", StringType(),True)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473265d2-b459-4635-bc1f-b25de6b5c664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SYMBOL: string (nullable = true)\n",
      " |-- SERIES: string (nullable = true)\n",
      " |-- OPEN: double (nullable = true)\n",
      " |-- HIGH: double (nullable = true)\n",
      " |-- LOW: double (nullable = true)\n",
      " |-- CLOSE: double (nullable = true)\n",
      " |-- LAST: double (nullable = true)\n",
      " |-- PREVCLOSE: double (nullable = true)\n",
      " |-- TOTTRDQTY: integer (nullable = true)\n",
      " |-- TOTTRDVAL: double (nullable = true)\n",
      " |-- TIMESTAMP: string (nullable = true)\n",
      " |-- TOTALTRADES: integer (nullable = true)\n",
      " |-- ISIN: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 05:23:53 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 14, schema size: 13\n",
      "CSV file: hdfs://localhost:9000/asgStocks/cm21FEB2022bhav.csv\n",
      "[Stage 0:===========================================================(1 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+-----+-----+-----+-----+---------+---------+-------------+-----------+-----------+------------+\n",
      "|    SYMBOL|SERIES|OPEN| HIGH|  LOW|CLOSE| LAST|PREVCLOSE|TOTTRDQTY|    TOTTRDVAL|  TIMESTAMP|TOTALTRADES|        ISIN|\n",
      "+----------+------+----+-----+-----+-----+-----+---------+---------+-------------+-----------+-----------+------------+\n",
      "| 20MICRONS|    EQ|76.0|77.55|73.25| 74.1| 73.6|     77.2|   141872|1.061998695E7|21-FEB-2022|       2443|INE144J01027|\n",
      "|21STCENMGM|    EQ|33.3| 33.3| 33.3| 33.3| 33.3|    33.95|      415|      13819.5|21-FEB-2022|         24|INE253B01015|\n",
      "| 3IINFOLTD|    EQ|62.0| 63.4|59.05|59.05|59.05|    62.15|   753815| 4.47928636E7|21-FEB-2022|       4999|INE748C01038|\n",
      "+----------+------+----+-----+-----+-----+-----+---------+---------+-------------+-----------+-----------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stockDf= spark.read.format(\"csv\").option(\"header\", True).schema(stockSchema).load(\"hdfs://localhost:9000/asgStocks\")\n",
    "stockDf.printSchema()\n",
    "\n",
    "stockDf.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9596c313-1c01-4ff3-a241-6a89b04edc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SYMBOL: string (nullable = true)\n",
      " |-- SERIES: string (nullable = true)\n",
      " |-- OPEN: double (nullable = true)\n",
      " |-- HIGH: double (nullable = true)\n",
      " |-- LOW: double (nullable = true)\n",
      " |-- CLOSE: double (nullable = true)\n",
      " |-- LAST: double (nullable = true)\n",
      " |-- PREVCLOSE: double (nullable = true)\n",
      " |-- TOTTRDQTY: integer (nullable = true)\n",
      " |-- TOTTRDVAL: double (nullable = true)\n",
      " |-- TIMESTAMP: string (nullable = true)\n",
      " |-- TOTALTRADES: integer (nullable = true)\n",
      " |-- ISIN: string (nullable = true)\n",
      " |-- priceGain: double (nullable = true)\n",
      " |-- PriceGainP: double (nullable = true)\n",
      " |-- Date: timestamp (nullable = true)\n",
      "\n",
      "+----------+------+-------+--------+--------+-------+-------+---------+---------+-------------+-----------+-----------+------------+-------------------+-------------------+-------------------+\n",
      "|    SYMBOL|SERIES|   OPEN|    HIGH|     LOW|  CLOSE|   LAST|PREVCLOSE|TOTTRDQTY|    TOTTRDVAL|  TIMESTAMP|TOTALTRADES|        ISIN|          priceGain|         PriceGainP|               Date|\n",
      "+----------+------+-------+--------+--------+-------+-------+---------+---------+-------------+-----------+-----------+------------+-------------------+-------------------+-------------------+\n",
      "| 20MICRONS|    EQ|   76.0|   77.55|   73.25|   74.1|   73.6|     77.2|   141872|1.061998695E7|21-FEB-2022|       2443|INE144J01027|-1.9000000000000057|-2.5000000000000075|2022-02-21 00:00:00|\n",
      "|21STCENMGM|    EQ|   33.3|    33.3|    33.3|   33.3|   33.3|    33.95|      415|      13819.5|21-FEB-2022|         24|INE253B01015|                0.0|                0.0|2022-02-21 00:00:00|\n",
      "| 3IINFOLTD|    EQ|   62.0|    63.4|   59.05|  59.05|  59.05|    62.15|   753815| 4.47928636E7|21-FEB-2022|       4999|INE748C01038| -2.950000000000003|-4.7580645161290365|2022-02-21 00:00:00|\n",
      "|   3MINDIA|    EQ|21700.0|22240.85|21500.05|22156.3|22080.0| 21640.45|     3559|7.827183535E7|21-FEB-2022|       1906|INE470A01017|  456.2999999999993|  2.102764976958522|2022-02-21 00:00:00|\n",
      "|    3PLAND|    BE|  16.15|   16.95|    15.4|   16.5|  16.55|    16.15|     7200|     116645.2|21-FEB-2022|         71|INE105C01023| 0.3500000000000014| 2.1671826625387087|2022-02-21 00:00:00|\n",
      "+----------+------+-------+--------+--------+-------+-------+---------+---------+-------------+-----------+-----------+------------+-------------------+-------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/12 05:24:17 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 14, schema size: 13\n",
      "CSV file: hdfs://localhost:9000/asgStocks/cm21FEB2022bhav.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp\n",
    "#price Gain\n",
    "priceGainDf = stockDf.withColumn(\"priceGain\", col(\"CLOSE\")-col(\"OPEN\"))\\\n",
    "                     .withColumn(\"PriceGainP\", (col(\"priceGain\") / col(\"OPEN\")) * 100)\\\n",
    "                     .withColumn(\"Date\",to_timestamp((\"TIMESTAMP\"),\"dd-MMM-yyyy\"))\n",
    "                  \n",
    "priceGainDf.printSchema()\n",
    "priceGainDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e19580df-c6f6-4214-ae44-ceb75ac2975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:===============================================>       (172 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+------------------+-------------------+------+----------+------------------+\n",
      "|    SYMBOL|          priceGain|        PriceGainP|               Date|   lag|VolumeGain|       VolumeGainP|\n",
      "+----------+-------------------+------------------+-------------------+------+----------+------------------+\n",
      "|SREIBNPNCD|               40.0|              32.0|2022-02-25 00:00:00|    74|        91|122.97297297297298|\n",
      "|      RHFL|  67.69999999999999|28.771780705482357|2022-02-25 00:00:00|683740|   -683196| -99.9204375932372|\n",
      "|    FELDVR| 2.3499999999999996| 22.59615384615384|2022-02-28 00:00:00|202636|      8218| 4.055547878955369|\n",
      "|  MODISNME| 13.399999999999999|22.558922558922557|2022-02-28 00:00:00| 46827|     15539| 33.18384692591881|\n",
      "|  STEELCAS|  53.30000000000001| 22.39495798319328|2022-02-22 00:00:00|  1941|      1792|  92.3235445646574|\n",
      "|  FILDF2GP|0.21999999999999997| 22.22222222222222|2022-02-25 00:00:00|  1042|      1835| 176.1036468330134|\n",
      "|KOTHARIPRO|  19.35000000000001| 21.96367763904655|2022-03-02 00:00:00|  5552|    120102|2163.2204610951007|\n",
      "|  ATALREAL|  24.05000000000001|21.666666666666675|2022-02-24 00:00:00|  1600|      1600|             100.0|\n",
      "|  VAISHALI|  9.350000000000001|20.085929108485505|2022-02-23 00:00:00|213033|   1372282| 644.1640497012199|\n",
      "|KAMATHOTEL| 10.449999999999996|20.057581573896343|2022-02-18 00:00:00|     0|   1961648|              null|\n",
      "+----------+-------------------+------------------+-------------------+------+----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag, desc\n",
    "\n",
    "windowspec = Window.partitionBy(\"SYMBOL\").orderBy(\"DATE\")\n",
    "\n",
    "priceGainDf1 = priceGainDf.withColumn(\"lag\", lag(\"TOTTRDQTY\",1).over(windowspec))\\\n",
    "                          .na.fill(value=0,subset=[\"lag\"])\\\n",
    "                          .withColumn(\"VolumeGain\",col(\"TOTTRDQTY\") - col(\"lag\") )\\\n",
    "                          .withColumn(\"VolumeGainP\",col(\"VolumeGain\") / col(\"lag\") * 100)\\\n",
    "                          .drop(\"ISIN\", \"OPEN\", \"SERIES\", \"HIGH\", \"LOW\", \"CLOSE\", \"LAST\", \"PREVCLOSE\", \"TOTTRDQTY\", \"TOTTRDVAL\", \"TIMESTAMP\",\"TOTALTRADES\")\\\n",
    "                          .sort(desc(\"PriceGainP\"))\n",
    "\n",
    "priceGainDf1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26bf0e89-b4ba-4ae9-929d-3f7fb3c6daf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "priceGainDf1.write.mode(\"overwrite\")\\\n",
    "                    .json(\"hdfs://localhost:9000/Asg2VolumeGain-json\")\n",
    "\n",
    "priceGainDf1.write.mode(\"overwrite\")\\\n",
    "                    .parquet(\"hdfs://localhost:9000/Asg2VolumeGain-parquet\")\n",
    "\n",
    "priceGainDf1.write.mode(\"overwrite\")\\\n",
    "                    .orc(\"hdfs://localhost:9000/Asg2VolumeGain-orc\")\n",
    "\n",
    "priceGainDf1.write.mode(\"overwrite\")\\\n",
    "                    .csv(\"hdfs://localhost:9000/Asg2VolumeGain-csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bb328b-1673-4655-b04d-87e7d7d696f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
